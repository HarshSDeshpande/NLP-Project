{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def convert_to_image_prompt(summary: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a text summary into an image prompt using OpenAI's API.\n",
    "    \n",
    "    Args:\n",
    "    - summary (str): The text summary of the welfare scheme section.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The generated image prompt.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Convert the following text summary into a detailed, descriptive image prompt for \"\n",
    "        f\"a text-to-image generative model. This generative model will be used to create a poster for the welfare scheme mentioned especially for people who don't speak english. Do not add text to the poster. Make sure to include vivid visual elements, \"\n",
    "        f\"colors, expressions, and any relevant scene settings:\\n\\n\"\n",
    "        f\"Summary: {summary}\\n\\nImage prompt:\"\n",
    "    )\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant who has to convert a text summary into an image prompt for a text-to-image generative model. This generative model will be used to create a poster for the welfare scheme mentioned. Do not add text to the poster, this would make the poster more accessible to people who cannot read. ENSURE THAT THE PROMPT IS COMPLIANT WITH OPENAI'S POLICIES AND DOES NOT CONTAIN OFFENSIVE INFORMATION.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    image_prompt = response.choices[0].message.content\n",
    "    return image_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image prompt saved for scheme: MGNREGA as MGNREGA.txt\n",
      "Image prompt saved for scheme: ABPMJAY as ABPMJAY.txt\n",
      "Image prompt saved for scheme: NRLM as NRLM.txt\n",
      "Image prompt saved for scheme: AAY as AAY.txt\n",
      "Image prompt saved for scheme: DDUGKY as DDUGKY.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "summaries_directory = \"scheme_writeups_gpt\"\n",
    "image_prompts_directory = \"image_prompts\"\n",
    "\n",
    "os.makedirs(image_prompts_directory, exist_ok=True)\n",
    "\n",
    "def generate_image_prompts_from_summaries(summaries_dir, prompts_dir):\n",
    "    scheme_prompts = {}\n",
    "\n",
    "    for filename in os.listdir(summaries_dir):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            \n",
    "            scheme_name, section_name = filename.split('_', 1)\n",
    "            section_name = section_name.replace('.txt', '').replace('_', ' ')\n",
    "            \n",
    "            file_path = os.path.join(summaries_dir, filename)\n",
    "            \n",
    "            with open(file_path, \"r\") as summary_file:\n",
    "                summary_content = summary_file.read()\n",
    "                \n",
    "            if scheme_name not in scheme_prompts:\n",
    "                scheme_prompts[scheme_name] = []\n",
    "            scheme_prompts[scheme_name].append((section_name, summary_content))\n",
    "    \n",
    "    for scheme_name, sections in scheme_prompts.items():\n",
    "        full_summary = \"\\n\".join([f\"{section}: {content}\" for section, content in sections])\n",
    "        \n",
    "        image_prompt = convert_to_image_prompt(full_summary)        \n",
    "        prompt_filename = f\"{scheme_name}.txt\"\n",
    "        prompt_file_path = os.path.join(prompts_dir, prompt_filename)\n",
    "        \n",
    "        with open(prompt_file_path, \"w\") as prompt_file:\n",
    "            prompt_file.write(image_prompt)\n",
    "            \n",
    "        print(f\"Image prompt saved for scheme: {scheme_name} as {prompt_filename}\")\n",
    "\n",
    "generate_image_prompts_from_summaries(summaries_directory, image_prompts_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
