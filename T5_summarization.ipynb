{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (3.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\rudra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welfare scheme write-up loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the welfare scheme write-up from a text file\n",
    "file_path = \"AAY.txt\"  # Ensure the file is in the same directory\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    write_up = file.read()\n",
    "\n",
    "print(\"Welfare scheme write-up loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")  # You can use other versions like t5-base or t5-large as well\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_summary_with_t5(summary: str, prompt_section: str, **kwargs) -> str:\n",
    "    \"\"\"\n",
    "    Finalizes the summary by using T5 to refine and remove redundancies, ensuring fluency.\n",
    "    \n",
    "    Args:\n",
    "    - summary (str): The rough draft summary to be refined.\n",
    "    - prompt_section (str): Section prompt to provide context.\n",
    "    - kwargs: Additional parameters for the model's generate function.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The finalized, fluent summary.\n",
    "    \"\"\"\n",
    "    # Prepare the refinement prompt for T5\n",
    "    # refine_prompt = (\n",
    "    #     f\"Refine and condense the following summary for clarity, completeness, \"\n",
    "    #     f\"and to remove redundant information for the section: {prompt_section}.\\n\"\n",
    "    #     f\"Summary: {summary}\"\n",
    "    # )\n",
    "    # refine_prompt = (\n",
    "    #     f\"Remove repeating sentences  and finish incomplete sentences from the following text\\n\"\n",
    "    #     f\"text: {summary}\"\n",
    "    # )\n",
    "    refine_prompt = (\n",
    "        f\"Identify Key Information from the following \"\n",
    "        f\"text: {summary}\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize and ensure input fits within max length\n",
    "    inputs = tokenizer(refine_prompt, max_length=kwargs.get(\"max_length\", 512), truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    try:\n",
    "        # Generate the refined summary with parameters from **kwargs\n",
    "        summary_ids = model.generate(inputs.input_ids, **kwargs)\n",
    "        final_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during final refinement: {e}\")\n",
    "        final_summary = summary  # Fall back to the draft summary without further processing\n",
    "\n",
    "    # return f\"Original Summary : {summary}\\n Refined_summary : {final_summary}\"\n",
    "    return final_summary\n",
    "\n",
    "def get_summary_with_t5(write_up: str, prompt_section: str, window_size: int = 512, overlap: int = 50, max_summary_tokens: int = 200, **kwargs) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes the welfare scheme write-up based on the specified prompt section using T5.\n",
    "    This function uses a sliding window approach with dynamic chunk sizing to handle long texts, accumulating the summary as it progresses.\n",
    "\n",
    "    Args:\n",
    "    - write_up (str): Full write-up of the welfare scheme.\n",
    "    - prompt_section (str): The section prompt, e.g., \"Beneficiary and Problem Statement\".\n",
    "    - window_size (int): The maximum size for each model input.\n",
    "    - overlap (int): The number of tokens to overlap between segments.\n",
    "    - max_summary_tokens (int): Maximum tokens to retain in the accumulated summary for each input.\n",
    "    - kwargs: Additional parameters for the model's generate function.\n",
    "\n",
    "    Returns:\n",
    "    - str: The combined generated summary for the specified section.\n",
    "    \"\"\"\n",
    "    if not write_up or not prompt_section:\n",
    "        raise ValueError(\"Write-up and prompt section must not be empty.\")\n",
    "    \n",
    "    # Tokenize the entire write-up\n",
    "    total_tokens = tokenizer(write_up)[\"input_ids\"]\n",
    "    print(f\"Total tokens: {len(total_tokens)}\")  # Debugging line\n",
    "    \n",
    "    accumulated_summary = \"\"\n",
    "    summaries = []\n",
    "    start_idx = 0  # To keep track of the position in the tokenized write-up\n",
    "\n",
    "    # Process in sliding windows to handle long write-ups\n",
    "    while start_idx < len(total_tokens):\n",
    "        # Truncate accumulated summary to last max_summary_tokens tokens to fit within the model input\n",
    "        truncated_summary = tokenizer.decode(\n",
    "            tokenizer(accumulated_summary)[\"input_ids\"][-max_summary_tokens:], \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        # Prepare the prompt and summary context\n",
    "        prompt_text = (\n",
    "            f\"{prompt_section}.\\n\"\n",
    "            f\"Summary so far: {truncated_summary}\\n\"\n",
    "            f\"summarize: \"\n",
    "        )\n",
    "        \n",
    "        # Calculate remaining tokens for the current chunk\n",
    "        prompt_tokens = tokenizer(prompt_text)[\"input_ids\"]\n",
    "        available_chunk_size = window_size - len(prompt_tokens)\n",
    "        \n",
    "        # Extract the chunk with the available size\n",
    "        chunk = total_tokens[start_idx:start_idx + available_chunk_size]\n",
    "        if len(chunk) == 0:\n",
    "            break\n",
    "\n",
    "        # Decode the chunk back to text\n",
    "        chunk_text = tokenizer.decode(chunk, skip_special_tokens=True)\n",
    "        \n",
    "        # Combine prompt and chunk text\n",
    "        model_input = prompt_text + chunk_text\n",
    "        \n",
    "        # Tokenize the combined input for the model\n",
    "        inputs = tokenizer(model_input, max_length=window_size, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        try:\n",
    "            # Generate the summary for the current chunk\n",
    "            summary_ids = model.generate(inputs.input_ids, **kwargs)\n",
    "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Update the accumulated summary and add to the summaries list for debugging\n",
    "            accumulated_summary += \" \" + summary\n",
    "            summaries.append(summary)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating summary for chunk starting at token index {start_idx}: {e}\")\n",
    "        \n",
    "        # Move start index for the next chunk, applying overlap\n",
    "        start_idx += available_chunk_size - overlap\n",
    "    \n",
    "    # Final accumulated summary\n",
    "    final_summary = finalize_summary_with_t5(accumulated_summary.strip(), prompt_section,**kwargs)\n",
    "    return final_summary\n",
    "\n",
    "\n",
    "def summarize_scheme_with_t5(write_up: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generates summaries for each of the three sections using T5:\n",
    "    'Beneficiary and Problem Statement', 'Application Process and Benefits', 'Outcome and Impact'.\n",
    "    \n",
    "    Args:\n",
    "    - write_up (str): Full write-up of the welfare scheme.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing summaries for each section.\n",
    "    \"\"\"\n",
    "    sections = [\n",
    "        \"Beneficiary and Problem Statement\",\n",
    "        \"Application Process and Benefits\",\n",
    "        \"Outcome and Impact\"\n",
    "    ]\n",
    "    \n",
    "    section_prompts_t5 = {\n",
    "        f\"Beneficiary and Problem Statement\": \"Identify the key beneficiaries of the welfare scheme and the problems they face.\",\n",
    "        \"Application Process and Benefits\": \"Identify the application process and benefits provided by the scheme.\",\n",
    "        \"Outcome and Impact\": \" Identify the outcomes and impact of the scheme on its beneficiaries.\"\n",
    "    }\n",
    "    \n",
    "    summaries = {}\n",
    "    # Use tqdm to show progress for summarizing each section\n",
    "    for section, prompt in tqdm(section_prompts_t5.items(), desc=\"Summarizing Sections\"):\n",
    "        summaries[section] = get_summary_with_t5(write_up, prompt, max_length=80, min_length=20, num_beams=5, length_penalty=1.2, early_stopping=True)\n",
    "\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing Sections:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing Sections:  33%|███▎      | 1/3 [04:18<08:37, 258.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing Sections:  67%|██████▋   | 2/3 [07:40<03:45, 225.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing Sections: 100%|██████████| 3/3 [11:17<00:00, 225.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneficiary and Problem Statement:\n",
      "Original Summary : Antyodaya Anna Yojana (AAY) is a flagship food security program in india . it aims to provide highly subsidized food grains to the poorest of the poor . each eligible household can receive up to 35 kg of food grains per month . Antyodaya Anna Yojana (AAY) is a flagship food security program in india . it aims to provide highly subsidized food grains to the poorest of the poor . each eligible household can receive up to 35 kg of food grains per month . food grains, AAY plays a significant role in improving nutritional standards and alleviating poverty . it aims to provide highly subsidized food grains to the poorest of the poor . each eligible household can receive up to 35 kg of food grains per month .\n",
      " Refined_summary : Antyodaya Anna Yojana (AAY) is a flagship food security program in india . it aims to provide highly subsidized food grains to the poorest households . each eligible household can receive up to 35 kg of food grains per month .\n",
      "\n",
      "Application Process and Benefits:\n",
      "Original Summary : Antyodaya Anna Yojana (AAY) is a flagship food security program initiated by the government of india on December 25, 2000 . the scheme aims to provide highly subsidized food grains to the poorest of the poor households in the country . it is part of the larger public distribution system and focuses on ensuring that the most vulnerable sections of society the scheme aims to provide highly subsidized food grains to the poorest of the poor households in india . it is part of the larger public distribution system and focuses on ensuring that the most vulnerable sections of society are provided with food . despite its successes, the scheme faces several challenges: - Awareness and accessibility: many eligible households may not be aware of their rights the scheme aims to provide highly subsidized food grains to the poorest of the poor households in india . it is part of the larger public distribution system and focuses on ensuring that the most vulnerable sections of society are provided with food . continued efforts towards enhancing awareness, ensuring transparency in distribution, and addressing challenges will be essential .\n",
      " Refined_summary : (AAY) is a flagship food security program initiated by the government of india on December 25, 2000 . It aims to provide highly subsidized food grains to the poorest of the poor households in the country . is a flagship food security program initiated by the government of india on December 25, 2000 . . on providing food grains to the poor\n",
      "\n",
      "Outcome and Impact:\n",
      "Original Summary : Antyodaya Anna Yojana (AAY) aims to provide highly subsidized food grains to the poorest of the poor households in the country . it is part of the larger public distribution system (PDS) and focuses on ensuring that the most vulnerable sections of society have access to sufficient food . Antyodaya Anna Yojana (AAY) aims to provide highly subsidized food grains to the poorest of the poor in india . it is part of the larger public distribution system (PDS) and focuses on ensuring that the most vulnerable sections of society have access to sufficient food . providing highly subsidized food grains, AAY plays a significant role in improving nutritional standards and alleviating poverty . it is part of the larger public distribution system (PDS) and focuses on ensuring that the most vulnerable sections of society have access to sufficient food .\n",
      " Refined_summary : Anna Yojana (AAY) Anna Yojana (AAY) aims to provide highly subsidized food grains to the poorest of the poor households in the country .. Anna Yojana (AAY) aims to provide highly subsidized food grains to the poorest of the poor households in the country .. Anna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate summaries\n",
    "summaries = summarize_scheme_with_t5(write_up)\n",
    "\n",
    "# Display the summaries\n",
    "for section, summary in summaries.items():\n",
    "    print(f\"{section}:\\n{summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
