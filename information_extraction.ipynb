{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welfare scheme write-up loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the welfare scheme write-up from a text file\n",
    "file_path = \"AAY.txt\"  # Ensure the file is in the same directory\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    write_up = file.read()\n",
    "\n",
    "print(\"Welfare scheme write-up loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Set OpenAI API key (replace \"YOUR_API_KEY\" with your actual key)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Use environment variable or directly set API key\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "def get_summary(write_up: str, prompt_section: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes the welfare scheme write-up based on the specified prompt section.\n",
    "\n",
    "    Args:\n",
    "    - write_up (str): Full write-up of the welfare scheme.\n",
    "    - prompt_section (str): The section prompt, e.g., \"Beneficiary and Problem Statement\".\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated summary for the specified section.\n",
    "    \"\"\"\n",
    "    # Define prompt for each section\n",
    "    prompt = f\"Summarize the following welfare scheme description into the section '{prompt_section}':\\n\\n{write_up}\\n\\n\"\n",
    "\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary\n",
    "\n",
    "def summarize_scheme_with_openai(write_up: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generates summaries for each of the three sections: \n",
    "    'Beneficiary and Problem Statement', 'Application Process and Benefits', 'Outcome and Impact'.\n",
    "    \"\"\"\n",
    "    sections = [\n",
    "        \"Beneficiary and Problem Statement\",\n",
    "        \"Application Process and Benefits\",\n",
    "        \"Outcome and Impact\"\n",
    "    ]\n",
    "    \n",
    "    summaries = {}\n",
    "    for section in sections:\n",
    "        summaries[section] = get_summary(write_up, section)\n",
    "    \n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate summaries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m summaries \u001b[38;5;241m=\u001b[39m summarize_scheme_with_openai(write_up)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display the summaries\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m section, summary \u001b[38;5;129;01min\u001b[39;00m summaries\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[23], line 51\u001b[0m, in \u001b[0;36msummarize_scheme_with_openai\u001b[0;34m(write_up)\u001b[0m\n\u001b[1;32m     49\u001b[0m summaries \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m sections:\n\u001b[0;32m---> 51\u001b[0m     summaries[section] \u001b[38;5;241m=\u001b[39m get_summary(write_up, section)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m summaries\n",
      "Cell \u001b[0;32mIn[23], line 25\u001b[0m, in \u001b[0;36mget_summary\u001b[0;34m(write_up, prompt_section)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Define prompt for each section\u001b[39;00m\n\u001b[1;32m     23\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize the following welfare scheme description into the section \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_section\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mwrite_up\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 25\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     26\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     29\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[1;32m     30\u001b[0m     n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     31\u001b[0m     stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m summary \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m summary\n",
      "File \u001b[0;32m~/miniconda3/envs/NLPproject/lib/python3.12/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'engine'"
     ]
    }
   ],
   "source": [
    "# Generate summaries\n",
    "summaries = summarize_scheme_with_openai(write_up)\n",
    "\n",
    "# Display the summaries\n",
    "for section, summary in summaries.items():\n",
    "    print(f\"{section}:\\n{summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
