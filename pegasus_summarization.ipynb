{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welfare scheme write-up loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the welfare scheme write-up from a text file\n",
    "file_path = \"AAY.txt\"  # Ensure the file is in the same directory\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    write_up = file.read()\n",
    "\n",
    "print(\"Welfare scheme write-up loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/miniconda3/envs/NLPproject/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading Tokenizer: 100%|██████████| 1/1 [00:01<00:00,  1.04s/model]\n",
      "Loading Model:   0%|          | 0/1 [00:00<?, ?model/s]Error while downloading from https://cdn-lfs.hf.co/google/pegasus-xsum/f19169fbf6d5bf3b3c713cb933e40a5fa22ffdb6e0d7628309e2deabc5978e59?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1731409095&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQwOTA5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy14c3VtL2YxOTE2OWZiZjZkNWJmM2IzYzcxM2NiOTMzZTQwYTVmYTIyZmZkYjZlMGQ3NjI4MzA5ZTJkZWFiYzU5NzhlNTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=b-sXwOKjmJLolQcwX4KI-WJ3Acx2KncVjL2Y91DKfo-ghKxU0W0YsShujucZQPOyZ19nYtj59n26OaeXQELNYAMs5vhz9EnSJiRaiyEOfGptYNvtuILHOOEbAYAvvWNnB0HWZbfPVWGcyaY9dn5OdZBlyaMb0zjs0VByltmFL%7ECQu2fFiUkVRsK2jnuvib0Pyiem3yBNw6PQNpFIhhCal9RkERKRwE9GVjReNXF5qzrJb9PGE2nGQsLupY-EOC8PZ2nrySOjAZYnUDLV1JyyAozr2K-Ge0V%7EUz%7EQw3MyNfeUvcC9ZoxAvQ4yROZw-kl84RduKtnTzIhujVs60Rsd5Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/google/pegasus-xsum/f19169fbf6d5bf3b3c713cb933e40a5fa22ffdb6e0d7628309e2deabc5978e59?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1731409095&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQwOTA5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy14c3VtL2YxOTE2OWZiZjZkNWJmM2IzYzcxM2NiOTMzZTQwYTVmYTIyZmZkYjZlMGQ3NjI4MzA5ZTJkZWFiYzU5NzhlNTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=b-sXwOKjmJLolQcwX4KI-WJ3Acx2KncVjL2Y91DKfo-ghKxU0W0YsShujucZQPOyZ19nYtj59n26OaeXQELNYAMs5vhz9EnSJiRaiyEOfGptYNvtuILHOOEbAYAvvWNnB0HWZbfPVWGcyaY9dn5OdZBlyaMb0zjs0VByltmFL%7ECQu2fFiUkVRsK2jnuvib0Pyiem3yBNw6PQNpFIhhCal9RkERKRwE9GVjReNXF5qzrJb9PGE2nGQsLupY-EOC8PZ2nrySOjAZYnUDLV1JyyAozr2K-Ge0V%7EUz%7EQw3MyNfeUvcC9ZoxAvQ4yROZw-kl84RduKtnTzIhujVs60Rsd5Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/google/pegasus-xsum/f19169fbf6d5bf3b3c713cb933e40a5fa22ffdb6e0d7628309e2deabc5978e59?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1731409095&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQwOTA5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy14c3VtL2YxOTE2OWZiZjZkNWJmM2IzYzcxM2NiOTMzZTQwYTVmYTIyZmZkYjZlMGQ3NjI4MzA5ZTJkZWFiYzU5NzhlNTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=b-sXwOKjmJLolQcwX4KI-WJ3Acx2KncVjL2Y91DKfo-ghKxU0W0YsShujucZQPOyZ19nYtj59n26OaeXQELNYAMs5vhz9EnSJiRaiyEOfGptYNvtuILHOOEbAYAvvWNnB0HWZbfPVWGcyaY9dn5OdZBlyaMb0zjs0VByltmFL%7ECQu2fFiUkVRsK2jnuvib0Pyiem3yBNw6PQNpFIhhCal9RkERKRwE9GVjReNXF5qzrJb9PGE2nGQsLupY-EOC8PZ2nrySOjAZYnUDLV1JyyAozr2K-Ge0V%7EUz%7EQw3MyNfeUvcC9ZoxAvQ4yROZw-kl84RduKtnTzIhujVs60Rsd5Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading Model: 100%|██████████| 1/1 [04:34<00:00, 274.59s/model]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/google/pegasus-xsum/46923d7498c8a594e3f467e2e48f7d82685a1ff19a060a5102dffa2a479ab6a9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731409371&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQwOTM3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy14c3VtLzQ2OTIzZDc0OThjOGE1OTRlM2Y0NjdlMmU0OGY3ZDgyNjg1YTFmZjE5YTA2MGE1MTAyZGZmYTJhNDc5YWI2YTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=PRjUnjV8s8-k0iJJ%7E2szLv2m2MCC6A95hsVu8orglYS6-m-aQXpeK9VtQjdrxBsM--oVF8CicfG3RsAXyAFT7ma3-3H6KTAnHbrz404cGGRlBFpiZ3%7EWBg34nOmB2px-W5HhQ8YvHLQLdMpFChaozMc4OyznF4BVgPM6DZW52tqY0fUN2SDKMtb7sgwSkHq-3cdrLgUldXDdv8aI90dDuD%7E3TiQ5AjGCLim%7EWeMx-Xir4Rmo5JbMk043iqJkD5p1%7EOOtVIEigOobCFBDwcFe90LD4P3k25pJfX9FKJPmkobK3zYrusQBKWcyIakC-rxf4U2q9Dan-u8qlb8IOepy8Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/google/pegasus-xsum/46923d7498c8a594e3f467e2e48f7d82685a1ff19a060a5102dffa2a479ab6a9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731409371&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQwOTM3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy14c3VtLzQ2OTIzZDc0OThjOGE1OTRlM2Y0NjdlMmU0OGY3ZDgyNjg1YTFmZjE5YTA2MGE1MTAyZGZmYTJhNDc5YWI2YTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=PRjUnjV8s8-k0iJJ%7E2szLv2m2MCC6A95hsVu8orglYS6-m-aQXpeK9VtQjdrxBsM--oVF8CicfG3RsAXyAFT7ma3-3H6KTAnHbrz404cGGRlBFpiZ3%7EWBg34nOmB2px-W5HhQ8YvHLQLdMpFChaozMc4OyznF4BVgPM6DZW52tqY0fUN2SDKMtb7sgwSkHq-3cdrLgUldXDdv8aI90dDuD%7E3TiQ5AjGCLim%7EWeMx-Xir4Rmo5JbMk043iqJkD5p1%7EOOtVIEigOobCFBDwcFe90LD4P3k25pJfX9FKJPmkobK3zYrusQBKWcyIakC-rxf4U2q9Dan-u8qlb8IOepy8Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/google/pegasus-xsum/46923d7498c8a594e3f467e2e48f7d82685a1ff19a060a5102dffa2a479ab6a9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731409371&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQwOTM3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy14c3VtLzQ2OTIzZDc0OThjOGE1OTRlM2Y0NjdlMmU0OGY3ZDgyNjg1YTFmZjE5YTA2MGE1MTAyZGZmYTJhNDc5YWI2YTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=PRjUnjV8s8-k0iJJ%7E2szLv2m2MCC6A95hsVu8orglYS6-m-aQXpeK9VtQjdrxBsM--oVF8CicfG3RsAXyAFT7ma3-3H6KTAnHbrz404cGGRlBFpiZ3%7EWBg34nOmB2px-W5HhQ8YvHLQLdMpFChaozMc4OyznF4BVgPM6DZW52tqY0fUN2SDKMtb7sgwSkHq-3cdrLgUldXDdv8aI90dDuD%7E3TiQ5AjGCLim%7EWeMx-Xir4Rmo5JbMk043iqJkD5p1%7EOOtVIEigOobCFBDwcFe90LD4P3k25pJfX9FKJPmkobK3zYrusQBKWcyIakC-rxf4U2q9Dan-u8qlb8IOepy8Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/google/pegasus-xsum/46923d7498c8a594e3f467e2e48f7d82685a1ff19a060a5102dffa2a479ab6a9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731409371&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQwOTM3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy14c3VtLzQ2OTIzZDc0OThjOGE1OTRlM2Y0NjdlMmU0OGY3ZDgyNjg1YTFmZjE5YTA2MGE1MTAyZGZmYTJhNDc5YWI2YTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=PRjUnjV8s8-k0iJJ%7E2szLv2m2MCC6A95hsVu8orglYS6-m-aQXpeK9VtQjdrxBsM--oVF8CicfG3RsAXyAFT7ma3-3H6KTAnHbrz404cGGRlBFpiZ3%7EWBg34nOmB2px-W5HhQ8YvHLQLdMpFChaozMc4OyznF4BVgPM6DZW52tqY0fUN2SDKMtb7sgwSkHq-3cdrLgUldXDdv8aI90dDuD%7E3TiQ5AjGCLim%7EWeMx-Xir4Rmo5JbMk043iqJkD5p1%7EOOtVIEigOobCFBDwcFe90LD4P3k25pJfX9FKJPmkobK3zYrusQBKWcyIakC-rxf4U2q9Dan-u8qlb8IOepy8Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/google/pegasus-xsum/46923d7498c8a594e3f467e2e48f7d82685a1ff19a060a5102dffa2a479ab6a9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731409371&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQwOTM3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy14c3VtLzQ2OTIzZDc0OThjOGE1OTRlM2Y0NjdlMmU0OGY3ZDgyNjg1YTFmZjE5YTA2MGE1MTAyZGZmYTJhNDc5YWI2YTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=PRjUnjV8s8-k0iJJ%7E2szLv2m2MCC6A95hsVu8orglYS6-m-aQXpeK9VtQjdrxBsM--oVF8CicfG3RsAXyAFT7ma3-3H6KTAnHbrz404cGGRlBFpiZ3%7EWBg34nOmB2px-W5HhQ8YvHLQLdMpFChaozMc4OyznF4BVgPM6DZW52tqY0fUN2SDKMtb7sgwSkHq-3cdrLgUldXDdv8aI90dDuD%7E3TiQ5AjGCLim%7EWeMx-Xir4Rmo5JbMk043iqJkD5p1%7EOOtVIEigOobCFBDwcFe90LD4P3k25pJfX9FKJPmkobK3zYrusQBKWcyIakC-rxf4U2q9Dan-u8qlb8IOepy8Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Load the Pegasus tokenizer and model with tqdm progress bar\n",
    "model_name = \"google/pegasus-xsum\"\n",
    "\n",
    "# Use tqdm to show progress for loading the tokenizer\n",
    "with tqdm(total=1, desc=\"Loading Tokenizer\", unit=\"model\") as pbar:\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "    pbar.update(1)  # Update progress\n",
    "\n",
    "# Use tqdm to show progress for loading the model\n",
    "with tqdm(total=1, desc=\"Loading Model\", unit=\"model\") as pbar:\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "    pbar.update(1)  # Update progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "def get_summary_with_pegasus(write_up: str, prompt_section: str, window_size: int = 512, overlap: int = 50, **kwargs) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes the welfare scheme write-up based on the specified prompt section using Pegasus.\n",
    "    This function uses a sliding window approach to handle long texts.\n",
    "\n",
    "    Args:\n",
    "    - write_up (str): Full write-up of the welfare scheme.\n",
    "    - prompt_section (str): The section prompt, e.g., \"Beneficiary and Problem Statement\".\n",
    "    - window_size (int): The size of each segment to summarize.\n",
    "    - overlap (int): The number of tokens to overlap between segments.\n",
    "    - kwargs: Additional parameters for the model's generate function.\n",
    "\n",
    "    Returns:\n",
    "    - str: The combined generated summary for the specified section.\n",
    "    \"\"\"\n",
    "    # Customize the prompt for the section\n",
    "    if not write_up or not prompt_section:\n",
    "        raise ValueError(\"Write-up and prompt section must not be empty.\")\n",
    "    \n",
    "    prompt = f\"Summarize the write up {write_up} in light of this {prompt_section}\"\n",
    "    \n",
    "    # Tokenize the entire input to get its length\n",
    "    total_tokens = tokenizer(prompt)[\"input_ids\"]\n",
    "    \n",
    "    summaries = []\n",
    "    \n",
    "    # Process in sliding windows\n",
    "    for i in range(0, len(total_tokens), window_size - overlap):\n",
    "        # Get the current chunk of tokens\n",
    "        chunk = total_tokens[i:i + window_size]\n",
    "        if len(chunk) == 0:\n",
    "            break\n",
    "        \n",
    "        # Convert chunk back to string for summarization\n",
    "        chunk_text = tokenizer.decode(chunk, skip_special_tokens=True)\n",
    "        \n",
    "        # Tokenize the chunk for model input\n",
    "        inputs = tokenizer(chunk_text, max_length=1024, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        try:\n",
    "            # Generate summary with custom parameters\n",
    "            if inputs.input_ids.size(1) == 0:\n",
    "                continue  # Skip empty inputs\n",
    "            \n",
    "            summary_ids = model.generate(inputs.input_ids, **kwargs)\n",
    "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            summaries.append(summary)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating summary for chunk starting at index {i}: {e}\")\n",
    "    \n",
    "    # Combine all summaries into a single summary\n",
    "    final_summary = \" \".join(summaries)\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "def summarize_scheme_with_pegasus(write_up: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generates summaries for each of the three sections using Pegasus:\n",
    "    'Beneficiary and Problem Statement', 'Application Process and Benefits', 'Outcome and Impact'.\n",
    "    \n",
    "    Args:\n",
    "    - write_up (str): Full write-up of the welfare scheme.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing summaries for each section.\n",
    "    \"\"\"\n",
    "    sections = [\n",
    "        \"Beneficiary and Problem Statement\",\n",
    "        \"Application Process and Benefits\",\n",
    "        \"Outcome and Impact\"\n",
    "    ]\n",
    "    \n",
    "    summaries = {}\n",
    "    \n",
    "    # Use tqdm to show progress for summarizing each section\n",
    "    for section in tqdm(sections, desc=\"Summarizing Sections\"):\n",
    "        summaries[section] = get_summary_with_pegasus(write_up, section, max_length=60, num_beams=5, length_penalty=1.2, early_stopping=True)\n",
    "    \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing Sections: 100%|██████████| 3/3 [00:20<00:00,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneficiary and Problem Statement:\n",
      "The Antyodaya Anna Yojana (AAY) is a flagship food security program initiated by the Government of India on December 25, 2000. The Antyodaya Anna Yojana (AAY) is a flagship scheme of the Indian government aimed at addressing food insecurity among the poorest sections of society in India.\n",
      "\n",
      "Application Process and Benefits:\n",
      "The Antyodaya Anna Yojana (AAY) is a flagship food security program initiated by the Government of India on December 25, 2000. The Antyodaya Anna Yojana (AAY) is a flagship scheme of the Indian government aimed at addressing food insecurity among the poorest sections of society in India.\n",
      "\n",
      "Outcome and Impact:\n",
      "The Antyodaya Anna Yojana (AAY) is a flagship food security program initiated by the Government of India on December 25, 2000. The Antyodaya Anna Yojana (AAY) is a flagship scheme of the Indian government aimed at addressing food insecurity among the poorest sections of society in India.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate summaries\n",
    "summaries = summarize_scheme_with_pegasus(write_up)\n",
    "\n",
    "# Display the summaries\n",
    "for section, summary in summaries.items():\n",
    "    print(f\"{section}:\\n{summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
